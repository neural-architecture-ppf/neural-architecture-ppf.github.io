<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <title>ICCV 2021 Workshop on Neural Architectures: Past, Present and Future</title>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
    <link href="css/style.css" rel="stylesheet" type="text/css"/>
</head>

<body>

<div class="container">
    <table border="0" align="center">
        <tr>
            <td width="700" align="center" valign="middle"><h3>ICCV 2021 Workshop on</h3>
                <span class="title"><strong>Neural Architectures: Past, Present and Future</strong></span></td>
        </tr>
        <tr>
        <td colspan="3" align="center"><h3>Montreal, Canada<br>Full day, October 11th, 2021<br><br>
        <br><br>Our internal conference page at ICCV is <a href="">here</a></h3></td>
        </tr>
    </table>
    <br><p><img src="figures/schedule.png" width="1000" align="middle"></p>
</div>

</br>

<div class="container">
    <h2>Overview</h2>
    <div class="overview">
        <p>The surge of deep learning has largely benefited from the success of neural architecture design. By evolving from LeNet to AlexNet to VGG and to ResNet, neural architecture keeps incorporating novel designs of architectural elements and network topologies, leading to significant improvements in representation learning. Recently, the emergence of neural architecture search (NAS) further advances the representational capacity of neural networks, by changing the architecture design from the hand-crafted manner to automation. Despite remarkable achievements being made on various benchmark tasks, the development of neural architectures still faces several challenges. On the one hand, current neural architecture designs are not fully automatic yet. For instance, even with NAS, we still require tremendous knowledge from human experts on designing the architecture search space, defining search strategies and selecting training hyperparameters. On the other hand, existing neural architectures are severely exposed to the problems of lacking interpretability, vulnerability to adversarial examples, incapability of abstract reasoning, etc.</p>

        <p>In this workshop, we will focus on recent research and future directions on advancing the deep learning system, particularly from the perspective of neural architectures. We aim to bring experts from artificial intelligence, machine learning, deep learning, statistics, computer vision, and cognitive science communities together not only on discussing the current challenges of neural architecture designs, but also on charting out the blueprint of neural architectures for further bridging the gap between the human brain and neural networks.</p>

        <p>Topics of interests include, but are not limited to, the following diverse fields:</p>
        <ul>
            <li> Understanding of neural architecture designs for optimization </li>
            <li> Novel frameworks of neural architecture search </li>
            <li> Reproducibility in neural architecture search </li>
            <li> Efficient/Robust/Explainable neural architectures </li>
            <li> Biologically inspired learning frameworks </li>
            <li> Applications of novel neural architectures </li>
    </div>
</div>

</br>

<div class="container">
    <h2>Important Dates</h2>
    TBD
    
</div>

</br>

<div class="container">
    <h2>Awards</h2>
    TBD
    <!--
    <div class="schedule">
    <h3><p><strong><font color="orange"><li>Best Paper Award</li></font></strong></p></h3>
    <p><a href="http://?.pdf"><papertitle>?</papertitle></a>
    <a href="https://zoom.us/?"><strong><font color="orange">[zoom link]</font></strong></a>
    <br>? (?)</p>
    <h3><p><strong><font color="orange"><li>Best Extended Abstract</li></font></strong></p></h3>
    <p><a href="http://?.pdf"><papertitle>?</papertitle></a>
    <a href="https://zoom.us/?"><strong><font color="orange">[zoom link]</font></strong></a>
    <br>? (?)</p>
    <h3><p><strong><font color="orange"><li>Travel Award</li></font></strong></p></h3>
    <p>? (?)</p>
    </div>
    -->
</div>

</br>

<!--<div class="container">-->
<!--    <h2>Important Dates</h2>-->
<!--    TBA-->
<!--</div>-->

<!--</br>-->

<div class="container">
    <h2>Schedule</h2>
    TBD
    <!--
    <div class="schedule">
        <p><strong>08:30 - 08:40 &nbsp &nbsp &nbsp &nbsp <a href="https://www.youtube.com/watch?v=FCTf5MeIBFM&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=1">Opening Remark</a></strong></p>
        <p><strong>08:40 - 09:10 &nbsp  &nbsp &nbsp &nbsp <a href="https://www.youtube.com/watch?v=nCDJ-aRHwRc&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=2">Invited Talk 1: Alan Yuille - Defending Against Random Occluder Attacks</a></strong></p>
        <p><strong>09:10 - 09:40 &nbsp  &nbsp &nbsp &nbsp <a href="https://www.youtube.com/watch?v=iQrWtRDCQ1E&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=3">Invited Talk 2: Aleksander Madry -  What Do Our Models Learn?</a></strong></p>
        <p><strong>09:40 - 10:10 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=8mzZuyGh-ys&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=4">Invited Talk 3: Earlence Fernandes - Physical Attacks on Object Detectors</a></strong></p>
        <p><strong>10:10 - 10:40 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=I3lvCepkBS8&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=5">Invited Talk 4: Matthias Bethge - Testing Generalization</a></strong></p>
        <p><strong>10:40 - 11:10 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=AcI8dsWwUHQ&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=6">Panel Discussion I: Alan Yuille, Aleksander Madry, Earlence Fernandes and Matthias Bethge</a></strong></p>
        <p><strong>11:10 - 13:00 &nbsp &nbsp  &nbsp &nbsp Poster Session I</strong></p>
        <p><strong>13:00 - 14:00 &nbsp &nbsp  &nbsp &nbsp Lunch Break</strong></p>
        <p><strong>14:00 - 14:30 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=mhDAcpTDSiw&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=7">Invited Talk 5: Laurens van der Maaten - Adversarial Robustness: The End of the Early Years</a></strong></p>
        <p><strong>14:30 - 15:00 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=GeI0_M8DsHE&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=8">Invited Talk 6: Pin-Yu Chen - Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness</a></strong></p>
        <p><strong>15:00 - 15:30 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=lmhQWJmWfdw&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=9">Invited Talk 7: Cho-Jui Hsieh - Adversarial Robustness of Discrete Machine Learning Models</a></strong></p>
        <p><strong>15:30 - 16:00 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=Qa73AMyZ10k&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=10">Invited Talk 8: Boqing Gong - Towards Visual Recognition in the Wild: Long-Tailed Sources and Open Compound Targets</a></strong></p>
        <p><strong>16:00 - 16:30 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=vKskBYxoY84&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=11">Invited Talk 9: Thomas G. Dietterich - Setting Alarm Thresholds for Anomaly Detection</a></strong></p>
        <p><strong>16:30 - 17:00 &nbsp &nbsp  &nbsp &nbsp <a href="https://www.youtube.com/watch?v=TASkCAc4WbM&list=PLT6XqV0BKKrKN7GwULt9Z6hVxYd3PSaoy&index=12">Panel Discussion II: Laurens van der Maaten, Pin-Yu Chen, Cho-Jui Hsieh, Boqing Gong and Thomas G. Dietterich</a></strong></p>
        <p><strong>17:00 - 18:50 &nbsp &nbsp  &nbsp &nbsp Poster Session II</strong></p>
        <p><strong>18:50 - 19:00 &nbsp &nbsp  &nbsp &nbsp Closing Remark</strong></p>
    </div>
    -->
</div>


</br>
<div class="container">
<h2>Accepted Papers</h2>
TBD
</div>

<!--</br>-->
<!--<div class="container">-->
<!--    <h2>Call For Papers</h2>-->
<!--    <div class="call4papers">-->
<!--<!--        <p><font color="red">We recently received many inquiries about the ddl extension for the paper submission, due to the inconvenience brought by the breakout of COVID-19. We understand this hard situation for all researchers, and decide to allow 1 more week for the paper submission. This deadline is firm and will not be extended futher. If you need any other accommodations, please let us know and we will try our best to help.</font></p>-->-->
<!--        <p><strong>Submission deadline</strong>: March 15 (<strong><font color="red">NEW: March 22</font></strong>), 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Notification sent to authors</strong>: April 3, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Camera ready deadline</strong>: April 10, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Notification sent to authors</strong>: April 10, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Camera ready deadline</strong>: April 17, 2020 Anywhere on Earth (AoE)</p>-->
<!--        <p><strong>Submission server</strong>: <a href="https://cmt3.research.microsoft.com/CVPRamlcv2020">https://cmt3.research.microsoft.com/CVPRamlcv2020</a></p>-->
<!--        <p><strong>Submission format</strong>: Submissions need to be <strong>anonymized</strong>, and follow the <a href="http://cvpr2020.thecvf.com/submission/main-conference/author-guidelines">CVPR 2020 Submission Guidelines</a>. The workshop considers two types of submissions: (1) <font color="orange"><strong>Long Paper</strong></font>: the page limitation is eight excluding references, and will be included in the official CVPR proceedings; (2) <font color="orange"><strong>Extended Abstract</strong></font>: the page limitation is four excluding references, and will <strong>NOT</strong> be included in the official CVPR proceedings. Based on the PC’s recommendation, the accepted long paper/extended abstract will be allocated either a contributed talk or a poster presentation.</p>-->
<!--        -->
<!--        <p>We invite submissions on <strong>any aspect of adversarial machine learning in computer vision</strong>. This includes, but is not limited to:</p>-->
<!--        <ul>-->
<!--            <li>Adversarial attacks on computer vision models in the digital/physical world</li>-->
<!--            <li>Improving model robustness against adversarial attacks</li>-->
<!--            <li>Theoretical understanding of adversarial machine learning</li>-->
<!--            <li>Applying adversarial machine learning to diagnosing/explaining computer vision models</li>-->
<!--            <li>Improving representation learning via adversarial machine learning </li>-->
<!--            <li>Applications of adversarial machine learning in computer vision tasks (e.g., generative models, image captioning, image recognition)</li>-->
<!--        </ul>-->
<!--        -->
<!--        <p><font color="red">We are excited to announce a <strong>DeepMind Best Paper Award and travel grants</strong>. The workshop is fully sponsored by DeepMind through the University of Oxford.</font></p>-->
<!--        <ul>-->
<!--            <li>The best paper award will be selected from long papers only. The winner will receive the <strong>US$ 1,500 prize and a certificate</strong> at the workshop’s closing.</li>-->
<!--            <li>The workshop has several travel grants (US$100 ~ $200 each) for authors. The travel grants will be considered especially for those from underrepresented groups, such as women and minority ethnic groups.</li>-->
<!--        </ul>-->
<!--    </div>-->
<!--</div>-->

</br>

<div class="container">
    <h2>Speakers</h2>
    TBD
    <!--
    <div>
        <div class="instructor">
            <a href="http://www.cs.jhu.edu/~ayuille/index.html">
                <div class="instructorphoto"><img src="figures/alanyuille.png"></div>
                <div>Alan Yuille<br>Johns Hopkins University</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://people.csail.mit.edu/madry/">
                <div class="instructorphoto"><img src="figures/aleksandermadry.jpg"></div>
                <div>Aleksander Mądry<br>MIT</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://www.earlence.com/">
                <div class="instructorphoto"><img src="figures/earlencefernandes.jpg"></div>
                <div>Earlence Fernandes<br>UW–Madison</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://bethgelab.org/people/matthias/">
                <div class="instructorphoto"><img src="figures/matthiasbethge.jpg"></div>
                <div>Matthias Bethge<br>University of Tübingen</div>
            </a>
        </div>
    </div>
    <div>
        <div class="instructor">
            <a href="https://lvdmaaten.github.io/">
                <div class="instructorphoto"><img src="figures/laurensvandermaaten.png"></div>
                <div>Laurens van der Maaten<br>Facebook AI Research</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://sites.google.com/site/pinyuchenpage">
                <div class="instructorphoto"><img src="figures/pinyuchen.jpg"></div>
                <div>Pin-Yu Chen<br>IBM</div>
            </a>
        </div>
            
        <div class="instructor">
            <a href="http://web.cs.ucla.edu/~chohsieh/">
                <div class="instructorphoto"><img src="figures/chojuihsieh.jpeg"></div>
                <div>Cho-Jui Hsieh<br>UCLA</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://boqinggong.info/">
                <div class="instructorphoto"><img src="figures/boqinggong.png"></div>
                <div>Boqing Gong<br>Google</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="http://web.engr.oregonstate.edu/~tgd/">
                <div class="instructorphoto"><img src="figures/thomasdietterich.jpg"></div>
                <div>Thomas G. Dietterich<br>Oregon State University</div>
            </a>
        </div>
    </div>
    -->
</div>

<!--</br>-->
<!---->
<!--<div class="container">-->
<!--    <h2>Schedule</h2>-->
<!--    TBD-->
<!--    <!--    <div class="schedule">-->-->
<!--    <!--        TBD-->-->
<!--    <!--        <p><span class="announce_date">8:40 - 9:00</span>. Opening Remarks</p>-->-->
<!--    <!--        <p><strong>Session 1: Adversarial Attacks against Computer Vision Systems</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 2: Improving Model Robustness</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 3: Understanding the Limitation of Computer Vision Models</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--        <p><strong>Session 4: Interpretable and Explainable Representation Learning</strong></p>-->-->
<!--    <!--        <p><span class="announce_date">9:00 - 9:30 </span>. Invited Talk #1: Prof. Earlence Fernandes</p>-->-->
<!--    <!--        <p><span class="announce_date">9:30 - 10:00</span>. Invited Talk #2: Dr. Boqing Gong </p>-->-->
<!--    <!--        <p><span class="announce_date">10:00 - 10:15</span>. Contributed Talk #1 </p>-->-->
<!--    <!--        <p><span class="announce_date">10:15 - 10:30</span>. Coffee Break </p>-->-->
<!--    <!--    </div>-->-->
<!--</div>-->

</br>

<div class="container">
    <h2>Organizing Committee</h2>
    <div>
        <div class="instructor">
            <a href="https://cihangxie.github.io/">
                <div class="instructorphoto"><img src="figures/cihangxie.jpg"></div>
                <div>Cihang Xie<br>University of California, Santa Cruz</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://xuanyidong.com/">
                <div class="instructorphoto"><img src="figures/xuanyidong.jpg"></div>
                <div>Xuanyi Dong<br>University of Technology Sydney</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://https://xiaocw11.github.io//">
                <div class="instructorphoto"><img src="figures/chaoweixiao.jpg"></div>
                <div>Chaowei Xiao<br>NVIDIA<br>Research</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://liulu112601.github.io/">
                <div class="instructorphoto"><img src="figures/luliu.jpg"></div>
                <div>Lu Liu<br>University of Technology Sydney</div>
            </a>
        </div>

        <div class="instructor">
            <a href="http://kaiminghe.com/">
                <div class="instructorphoto"><img src="figures/azadenazi.jpg"></div>
                <div>Azade Nazi<br>Google<br>Brain</div>
            </a>
        </div>
    </div>

    <p></p>
    <div>
        <div class="instructor">
            <a href="https://lingxixie.com/">
                <div class="instructorphoto"><img src="figures/lingxixie.jpg"></div>
                <div>Lingxi Xie<br>Huawei Inc.</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://research.google/people/105445/">
                <div class="instructorphoto"><img src="figures/mingxingtan.png"></div>
                <div>Mingxing Tan<br>Google Brain</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://tfwu.github.io/">
                <div class="instructorphoto"><img src="figures/tianfuwu.jpg"></div>
                <div>Tianfu Wu<br>NC State University</div>
            </a>
        </div>

        <div class="instructor">
            <a href="https://cs.stanford.edu/~quocle/">
                <div class="instructorphoto"><img src="figures/quocle.png"></div>
                <div>Quoc V Le<br>Google Brain</div>
            </a>
        </div>
    </div>
</div>
</br>

<div class="container">
    <h2>Program Committee</h2>
    TBD
    <!--
    <div class="pcs-row pcs">
        <div class="pcs-column">
            <ul>
                <li>Maksym Andriushchenko (EPFL)</li>
                <li>Anurag Arnab (Google)</li>
                <li>Arjun Nitin Bhagoji (Princeton University)</li>
                <li>Wieland Brendel (University of Tübingen)</li>
                <li>Yulong Cao (University of Michigan)</li>
                <li>Hongge Chen (MIT)</li>
                <li>Ambra Demontis (University of Cagliari)</li>
                <li>Yinpeng Dong (Tsinghua University)</li>
                <li>Sven Gowal (DeepMind)</li>
                <li>Chuan Guo (Cornell University)</li>
                <li>Saumya Jetley (INRIA)</li>
                <li>Adam Kortylewski (Johns Hopkins University)</li>
                <li>Alexey Kurakin (Google Brain)</li>
                <li>Yingwei Li (Johns Hopkins University)</li>
                <li>Jingyue Lu (University of Oxford)</li>
                <li>Jan Hendrik Metzen (Bosch Center for Artificial Intelligence)</li>
                <li>Mahyar Najibi (University of Maryland, College Park)</li>
                <li>Tianyu Pang (Tsinghua University)</li>
                <li>Maura Pintor (University of Cagliari)</li>
            </ul>
        </div>
        <div class="pcs-column">
            <ul>
                <li>Hamed Pirsiavash (UMBC)</li>
                <li>Omid Poursaeed (Cornell University)</li>
                <li>Aaditya Prakash (PathAI)</li>
                <li>Chongli Qin (DeepMind)</li>
                <li>Jonas Rauber (University of Tübingen)</li>
                <li>Aniruddha Saha (UMBC)</li>
                <li>Ali Shafahi (University of Maryland, College Park)</li>
                <li>Yash Sharma (University of Tübingen)</li>
                <li>Akshayvarun Subramanya (UMBC)</li>
                <li>Krishna Kumar Singh (UC Davis)</li>
                <li>David Stutz (Max Planck Institute for Informatics)</li>
                <li>Peng Tang (Salesforce Research)</li>
                <li>Jianyu Wang (Waymo)</li>
                <li>Yuxin Wu (Facebook AI Research)</li>
                <li>Chang Xiao (Columbia University)</li>
                <li>Chaowei Xiao (University of Michigan)</li>
                <li>Hongyang Zhang (Toyota Technological Institute at Chicago)</li>
                <li>Huan Zhang (UCLA)</li>
                <li>Dan Xu (University of Oxford)</li>    
            </ul>
        </div>
    </div>
    -->
</div>

</br>

<div class="container">
    <h2>Sponsor</h2>
    TBD
    <!--
    <div><img width="350" src="figures/DeepMind_RGB_Lockup_LogoHiRes_Blue.png"></div>
    -->
</div>

</br>

<div class="containersmall">
    <p>Please contact <a href="mailto:198808xc@gmail.com">Lingxi Xie</a> or <a href="mailto:cihangxie306@gmail.com">Cihang Xie</a> if you have questions. The webpage template
        is by the courtesy of <a href="https://interpretablevision.github.io/">ICCV 2019 Tutorial on Interpretable
            Machine Learning for Computer Vision</a>.</p>
</div>

<!--<p align="center" class="acknowledgement">Last updated: Jan. 6, 2017</p>-->
</body>
</html>
